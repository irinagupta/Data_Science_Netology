{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг Ведомостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем расширения для Chrome для удобного парсинга http://selectorgadget.com (+ используем fromstring из либы lxml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем мультипоточно качать сразу по 50 статей с сайта одновременно (Pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from multiprocessing.dummy import Pool\n",
    "from lxml.html import fromstring\n",
    "\n",
    "def get_page(url):\n",
    "    html = requests.get(url).text\n",
    "    dom = fromstring(html)\n",
    "    dom.make_links_absolute(url)\n",
    "    return dom\n",
    "\n",
    "def get_article_urls(url_date):\n",
    "    pattern = '.b-article__title a'\n",
    "    dom = get_page(url_date)\n",
    "    return [t.attrib['href'] for t in dom.cssselect(pattern)]\n",
    "\n",
    "def get_article_text(url):\n",
    "    # todo: if 'video' or 'gallery' ... - return ''\n",
    "    pattern_header = 'h1'\n",
    "    patterns = ['.b-news-item__text_one p', '.b-social__layout-mutation p']\n",
    "    \n",
    "    try:\n",
    "        dom = get_page(url)\n",
    "    except:\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        header = dom.cssselect(pattern_header)[0].text_content().strip()\n",
    "    except:\n",
    "        header = \"\"\n",
    "\n",
    "    try:\n",
    "        css_elements = flatten([dom.cssselect(pattern) for pattern in patterns])\n",
    "        text = \"\\n\\n\".join([t.text_content().strip() for t in css_elements])\n",
    "    except:\n",
    "        text = \"\"\n",
    "\n",
    "    return header, text\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_date_template = 'https://www.vedomosti.ru/archive/{}/{}/{}'\n",
    "url_dates = []\n",
    "for y in [2016]:\n",
    "    for m in range(1,13):\n",
    "        for d in range(1,29):\n",
    "            url_dates.append(url_date_template.format(y,m,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = Pool(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 2.55 s, total: 17.8 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "url_articles = pool.map(get_article_urls, url_dates)\n",
    "url_articles = flatten(url_articles)\n",
    "url_articles = [url for url in url_articles if url.split('/')[4] not in {'galleries','video','online'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вот сколько ссылок на статьи теперь у нас есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d89439b8387e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0murl_articles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'url_articles' is not defined"
     ]
    }
   ],
   "source": [
    "url_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-553abe9c8bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_articles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'url_articles' is not defined"
     ]
    }
   ],
   "source": [
    "len(url_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ограничимся пока 10000 статьями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls = url_articles[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"url\": urls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"topic\"] = df.url.apply(lambda x: x.split('/')[3])\n",
    "df[\"format\"] = df.url.apply(lambda x: x.split('/')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "скачаем тексты статей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "headers_texts = pool.map(get_article_text, urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "объединим в датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"header\"] = [t[0] for t in headers_texts]\n",
    "df[\"text\"] = [t[1] for t in headers_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('vedomosti_archive.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "длина заголовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.header.apply(len).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "длина текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.apply(len).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "длина текста, крупнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.apply(len)<3000].text.apply(len).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лемматизация слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "приведём все слова в текстах к начальной форме слова - так мы сильно сократим размерность пространства признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "хоть pymorphy2 и достаточно быстрый, лучше его упаковывать в класс со своим кэшем (который хорошо бы ещё куда-то выгружать при окончании и загружать в начале работы, это можете доделать. Удобно для этих целей использовать json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MorphProvider:\n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "        self.morph = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        w = w.lower()\n",
    "        cached = self.cache.get(w)\n",
    "        if cached:\n",
    "            return cached\n",
    "        try:\n",
    "            morphed = self.morph.parse(w)[0].normal_form\n",
    "            self.cache[w] = morphed\n",
    "            return morphed\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def morph_string(self, s):\n",
    "        words = word_tokenize(s)\n",
    "        return \" \".join([self.__call__(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = MorphProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalized\"] = [morph.morph_string(t) for t in tqdm(df.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('vedomosti_archive.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Облако слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4 fun*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [w for w in \" \".join(df.normalized).split() if len(w)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(words).most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "def get_wordcloud(text,max_font_size=None):\n",
    "    wordcloud = WordCloud(max_font_size=max_font_size).generate(text)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wordcloud(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wordcloud(' '.join(words), max_font_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
