{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing \n",
    "\n",
    "https://github.com/maryszmary/nlp-netology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основные задачи\n",
    "\n",
    "### Классификация текстов\n",
    "   * Фильтрация спама\n",
    "   * Анализ тональности\n",
    "   * Определение интента\n",
    "   * По теме или жанру\n",
    "   \n",
    "### Кластеризация текстов\n",
    "   * Аггрегация новостей\n",
    "   * Рекомендации\n",
    "   \n",
    "### Извлечение информации\n",
    "   * Именованные сущности (NER), отношения\n",
    "   * Факты и события   \n",
    "\n",
    "### Другие приложения\n",
    "   * Машинный перевод\n",
    "   * Вопросно-ответные системы\n",
    "   * Саммаризация текстов\n",
    "   * Генерация текста\n",
    "   * Распознавание речи\n",
    "   * Проверка правописания (spell-checking)\n",
    "   * Распознавание символов (OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline\n",
    "\n",
    "![pipeline.png](nlp_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Обработка текста\n",
    "\n",
    "#### Уровень символов:\n",
    "   * Токенизация: разбиение текста на слова\n",
    "   * Разбиение текста на предложения\n",
    "   \n",
    "#### Уровень слов (морфология):\n",
    "   * Определение частей речи (POS-tagging)\n",
    "   * Снятие морфологической неоднозначности\n",
    "   \n",
    "#### Уровень предложений (синтаксис):\n",
    "   * Выделенние именных или глагольных групп (chunking)\n",
    "   * Выделенние семантических ролей\n",
    "   * Деревья составляющих и зависимостей\n",
    "   \n",
    "#### Уровень смысла (семантика и дискурс):\n",
    "   * Разрешение кореферентных связей\n",
    "   * Выделение синонимов\n",
    "   * Анализ аргументативных связей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основные проблемы\n",
    "\n",
    "* Неоднозначность\n",
    "    * Лексическая неоднозначность: *орган, парить, рожки, атлас*\n",
    "    * Морфологическая неоднозначность: *Хранение денег в банке. Что делают белки в клетке?*\n",
    "    * Синтаксическая неоднозначность: *Его удивил простой солдат.*\n",
    "* Неологизмы: *печеньки, заинстаграммить, репостнуть, расшарить, затащить, килорубли*\n",
    "* Разные варианты написания: *Россия, Российская Федерация, РФ*\n",
    "* Нестандартное написание: *каг дила?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Синтаксическая неоднозначность\n",
    "\n",
    "### I saw a man on the hill with a telescope\n",
    "\n",
    "![syntax_ambiguaty](syntax_ambg.jpg)\n",
    "\n",
    "    I saw the man. The man was on the hill. I was using a telescope.\n",
    "    I saw the man. I was on the hill. I was using a telescope.\n",
    "    I saw the man. The man was on the hill. The hill had a telescope.\n",
    "    I saw the man. I was on the hill. The hill had a telescope.\n",
    "    I saw the man. The man was on the hill. I saw him using a telescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# План курса\n",
    "\n",
    "1. Предварительная обработка текстов\n",
    "2. Извлечение ключевых слов и синтаксический анализ \n",
    "3. Векторная модель, тематическое моделирование\n",
    "4. Векторная модель, дистрибутивная семантика\n",
    "5. Классификация текстов\n",
    "6. Языковые модели \n",
    "7. Извлечение информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предварительная обработка текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-10 18:44:27--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2020-04-10 18:44:27--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc282cd3154135b60e07fc00fd0e.dl.dropboxusercontent.com/cd/0/inline/A1l5Us2ZzD-PVbZVALaqD7B9w0dwivNs_JIjWegaNO9tqAhcQzGqv1aXBPbhNFLl8qcF8qkatOJLf8PMw9_xwhVh2P8NrFgmwO8Ty09u9GPgwQ/file# [following]\n",
      "--2020-04-10 18:44:28--  https://uc282cd3154135b60e07fc00fd0e.dl.dropboxusercontent.com/cd/0/inline/A1l5Us2ZzD-PVbZVALaqD7B9w0dwivNs_JIjWegaNO9tqAhcQzGqv1aXBPbhNFLl8qcF8qkatOJLf8PMw9_xwhVh2P8NrFgmwO8Ty09u9GPgwQ/file\n",
      "Resolving uc282cd3154135b60e07fc00fd0e.dl.dropboxusercontent.com (uc282cd3154135b60e07fc00fd0e.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to uc282cd3154135b60e07fc00fd0e.dl.dropboxusercontent.com (uc282cd3154135b60e07fc00fd0e.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv’\n",
      "\n",
      "positive.csv        100%[===================>]  25.02M  8.33MB/s    in 3.0s    \n",
      "\n",
      "2020-04-10 18:44:33 (8.33 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
      "\n",
      "--2020-04-10 18:44:33--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2020-04-10 18:44:33--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc68d40bcecfb8e70805061ff195.dl.dropboxusercontent.com/cd/0/inline/A1kLElX2PotyThm77ocXOlyWzzh7BTLuKVCevW04KIXaeVKHAKCM85PKCFRqyDxt4oWhrNCFMWepS7OpwLddRF5tDqEFW7DRItppYN7IbQ-OYg/file# [following]\n",
      "--2020-04-10 18:44:34--  https://uc68d40bcecfb8e70805061ff195.dl.dropboxusercontent.com/cd/0/inline/A1kLElX2PotyThm77ocXOlyWzzh7BTLuKVCevW04KIXaeVKHAKCM85PKCFRqyDxt4oWhrNCFMWepS7OpwLddRF5tDqEFW7DRItppYN7IbQ-OYg/file\n",
      "Resolving uc68d40bcecfb8e70805061ff195.dl.dropboxusercontent.com (uc68d40bcecfb8e70805061ff195.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to uc68d40bcecfb8e70805061ff195.dl.dropboxusercontent.com (uc68d40bcecfb8e70805061ff195.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv’\n",
      "\n",
      "negative.csv        100%[===================>]  23.32M  7.92MB/s    in 2.9s    \n",
      "\n",
      "2020-04-10 18:44:37 (7.92 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226834, 2)\n",
      "(170125,)\n",
      "(56709,)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)',\n",
       " 'Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D',\n",
       " 'RT @KatiaCheh: Ну ты идиотка) я испугалась за тебя!!!',\n",
       " 'RT @digger2912: \"Кто то в углу сидит и погибает от голода, а мы ещё 2 порции взяли, хотя уже и так жрать не хотим\" :DD http://t.co/GqG6iuE2…',\n",
       " '@irina_dyshkant Вот что значит страшилка :D\\nНо блин,посмотрев все части,у тебя создастся ощущение,что авторы курили что-то :D']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ngram_range` отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "* ngram_range=(1, 1) -- униграммы<br/>\n",
    "* ngram_range=(3, 3) -- триграммы<br/>\n",
    "* ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В `vec.vocabulary_` лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('уже', 226611),\n",
       " ('николаевке', 168234),\n",
       " ('пока', 186962),\n",
       " ('всем', 115361),\n",
       " ('инэта', 140884),\n",
       " ('ставрополе', 215900),\n",
       " ('не', 165420),\n",
       " ('будет', 108492),\n",
       " ('чвсов', 236443),\n",
       " ('дороги', 127662),\n",
       " ('круть', 149851),\n",
       " ('буду', 108543),\n",
       " ('на', 161728),\n",
       " ('поля', 188163),\n",
       " ('смотреть', 212022),\n",
       " ('сентября', 208583),\n",
       " ('день', 124498),\n",
       " ('знаний', 138231),\n",
       " ('моды', 159434),\n",
       " ('http', 37860)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthursaprykin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.76      0.76     28211\n",
      "    positive       0.76      0.77      0.77     28498\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthursaprykin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.72      0.57     18308\n",
      "    positive       0.82      0.61      0.70     38401\n",
      "\n",
      "    accuracy                           0.65     56709\n",
      "   macro avg       0.65      0.67      0.64     56709\n",
      "weighted avg       0.71      0.65      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthursaprykin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75     26697\n",
      "    positive       0.79      0.75      0.77     30012\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз получилось хуже :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthursaprykin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.77      0.75     26908\n",
      "    positive       0.78      0.75      0.77     29801\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), min_df=3, max_df=0.4)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "Токенизировать -- значит, поделить текст на слова, или *токены*.\n",
    "\n",
    "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@first_timee', 'хоть', 'я', 'и', 'школота,', 'но', 'поверь,', 'у', 'нас', 'то', 'же', 'самое', ':D', 'общество', 'профилирующий', 'предмет', 'типа)']\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_0',\n",
       " '0_lilith_g',\n",
       " '0_о',\n",
       " '0bkpahm6ml',\n",
       " '0ddman0ut',\n",
       " '0imzp3crty',\n",
       " '0lexia0',\n",
       " '0pvgczivef',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '1000000',\n",
       " '1000р',\n",
       " '1001',\n",
       " '100500',\n",
       " '100lokal',\n",
       " '100гаруй',\n",
       " '100р']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем разбивать текст на слова с использованием регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-я]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'хоть я и школота но поверь у нас то же самое общество профилирующий предмет типа'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_only(df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', '9.5', 'or', '525,600', 'my', 'favorite', 'number', '?']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = u'Is 9.5 or 525,600 my favorite number?'\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В nltk вообще есть довольно много токенизаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer',\n",
       " 'WhitespaceTokenizer',\n",
       " 'WordPunctTokenizer']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 9.5 or 525,600 my favorite number ?\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import toktok\n",
    "\n",
    "toktok = toktok.ToktokTokenizer()\n",
    "text = u'Is 9.5 or 525,600 my favorite number?'\n",
    "print (toktok.tokenize(text, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они умеют выдавать индексы начала и конца каждого токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_tok = tokenize.WhitespaceTokenizer()\n",
    "list(wh_tok.span_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
    "\n",
    "Некторые токенизаторы ведут себя специфично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\", 'stop', 'me']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач это может быть полезно.\n",
    "\n",
    "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(a (b c))', 'd', 'e', '(f)']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самые частотные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69267),\n",
       " ('и', 54916),\n",
       " ('в', 52853),\n",
       " ('я', 52506),\n",
       " ('RT', 38070),\n",
       " ('на', 35715),\n",
       " ('http', 32992),\n",
       " ('что', 31472),\n",
       " ('...', 28773),\n",
       " ('с', 27177),\n",
       " ('а', 26592),\n",
       " ('меня', 20591),\n",
       " ('у', 18861),\n",
       " ('как', 18141),\n",
       " ('так', 16739),\n",
       " ('D', 16552),\n",
       " ('это', 16436),\n",
       " ('мне', 16247),\n",
       " ('все', 14695),\n",
       " ('ты', 13358)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "\n",
    "# freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "freq_dict.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закон Ципфа\n",
    "Эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В любом достаточно большом тексте ранг слова обратно пропорционален его частоте: $f = \\frac{a}{r}$\n",
    "\n",
    "$f$ – частота слова, $r$  – ранг слова, $a$  – параметр, для славянских языков – около 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "freqs = list(freq_dict.values())\n",
    "freqs = sorted(freqs, reverse = True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs[:300], range(300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закон Хипса\n",
    "\n",
    "С увеличением длины текста (количества токенов), количество слов увеличивается в соответствии с законом: $|V| = K*N^b$\n",
    "\n",
    "\n",
    "$N$  –  число токенов, $|V|$  – количество слов в словаре, $K, b$  –  параметры, обычно $K \\in [10,100], b \\in [0.4, 0.6]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226834/226834 [10:55<00:00, 346.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cnt = Counter()\n",
    "n_words = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(df.iterrows(), total = len(df)):\n",
    "    tokens = word_tokenize(row['text'])\n",
    "    cnt.update([token for token in tokens if token not in punctuation])\n",
    "    n_words.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAD8CAYAAACo9anUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4VeW1x/HvghDmeRIIMygCyhQmcW5VoLei1ipaBdFKrdW2t71WbXvVqrfX9la9crVYVAS0ijiCA0VUlIpMQZAZCZBAwkyYxwzr/nFe2iNNQiDDSU5+n+c5T/ZZ5937XS8nnJW993v2NndHRESkLFWJdQIiIlL5qPiIiEiZU/EREZEyp+IjIiJlTsVHRETKnIqPiIiUORUfEREpcyo+IiJS5lR8RESkzCXEOoGS1qRJE2/Xrl2s0xARqVAWLVq0092bllV/cVd82rVrR0pKSqzTEBGpUMwsvSz702E3EREpcyo+IiJS5lR8RESkzKn4iIhImVPxERGRMqfiIyIiZU7FR0REypyKj4hIBZe+6yCPvLeSPYeOxTqVIou7L5mKiFQG7s7cdbsYPyeNj1dvI6GKMbBDY77dtXmsUysSFR8RkQrkSHYu7yzOZMIXaazeup/GtRO5+5JO3DSgLc3q1Yh1ekV20uJjZjWA2UD10P4Nd3/QzCYAFwF7Q9Nb3H2JmRnwFDAUOBTiX4ZtjQR+G9o/6u4TQ7wPMAGoCXwA/Mzd3cwaAa8B7YA04Dp3313MMYuIVDhb9x7hpXlpvDJ/I7sPZXN2i3r88dpzubJHS2pUqxrr9E5ZUfZ8jgKXuvsBM6sGfG5m08Nr97j7Gye0HwJ0Do/+wFigfygkDwLJgAOLzGxaKCZjgduB+USKz2BgOnAf8LG7P2Zm94Xn957+cEVEKpbFG3fz4pw0Pli2hVx3Lju7OaMGtWdAh0ZE/tavmE5afNzdgQPhabXw8EJWGQZMCuvNM7MGZtYCuBiY6e5ZAGY2ExhsZp8C9dx9XohPAq4iUnyGhfUAJgKfouIjInEuOzeP6cu38uKcDSzeuIe61RMYeV47Rg5sR5vGtWKdXoko0jkfM6sKLAI6Ac+4+3wz+zHwX2b2APAxcJ+7HwVaAZuiVs8IscLiGfnEAZq7+5awvBWoGGfSREROw+6Dx3hlwUZempvO1n1HaN+kNr+7shvf65NEnerxdYq+SKNx91ygp5k1AN42s+7A/UQKQiIwjsgeycOllWg4B5TvHpeZjQZGA7Rp06a0UhARKRUrNu9l/OdpvL9sM0ey87igcxN+f013Lj6zGVWqVNxDa4U5pVLq7nvMbBYw2N3/FMJHzexF4D/C80ygddRqSSGWyT8PoR2PfxriSfm0B9hmZi3cfUs4dLe9gLzGESmAJCcnF3ZIUESkXMjNcz5etY3xczYwb30WtRKrck3vJG45rx1nNq8b6/RKXVFmuzUFskPhqQlcBvwhqigYkXM0y8Mq04C7zGwykQkHe0O7GcDvzaxhaHc5cL+7Z5nZPjMbQGTCwQjg/6K2NRJ4LPycWhKDFhGJlSPZubz1ZSZ/mb2O9F2HaFm/BvcP6cLwvm2oX6tarNMrM0XZ82kBTAznfaoAU9z9PTP7JBQmA5YAd4T2HxCZZp1KZKr1KIBQZB4BFoZ2Dx+ffADcyT+nWk8PD4gUnSlmdhuQDlx3ugMVEYml3QeP8fK8dCbOTWfngaP0SKrPf9zQiyHdzyChauW72IxFJqXFj+TkZNdttEWkvNiw8yAvfL6eNxZlcCQ7j4vPasrtF3TgvI6Ny9VUaTNb5O7JZdVffE2fEBEpB9ydRem7GTd7PTNXbaNalSpc3asVP7ygPZ0rwfmcolDxEREpIbl5zkertvHsZ+tYvHEPDWpV465LOnHzwLY0q1txLn1TFlR8RESK6fCxXN5anMGLc9JI3X6A1o1q8vCwblzbJ4laifqYzY/+VURETtPWvUd48YsNvDp/I/uO5NCtZT3G3NCLoZV0EsGpUPERETlFSzbtYeIXaby3dDO5ec7g7mdwy3nt6duuYbmaRFCeqfiIiBSBu/PZ1zsY++k65m/Iok71BH7Qvy23nd+e1o3i43prZUnFR0SkEEeyc5m6JJPn/76BtdsPcEa9Gvz2O2czvF+buLveWlnSv5yISD627TvCS3PTeWXBRrIOHuPsFvX40/d7cGWPliQm6HxOcan4iIhEWbJpDy/O2cD7SyP3z/lWl+bcOqgdA8vZl0IrOhUfEan0Trx/Tp3qCYwY2I6R57WlbePasU4vLqn4iEillXXwGK9G3T+nXeNaPPjdrlzbJ4m6NSrPRT5jQcVHRCqd1Vv3MWFOGm8vzuRoTh7nd2rCf13dnUvOit/755Q3Kj4iUink5jmfrN7Oi3M28MW6XdSoVoVreicxalDluH9OeaPiIyJxbf+RbKakZDDxizQ2Zh2iRf0a3Du4C8P7tqZh7cRYp1dpqfiISFxK23mQCV+k8XrKJg4ey6VP24b8avBZXNHtDKrp0jcxp+IjInHD3ZmTuosX52zgkzXbSahi/Nu5LRk1qB3nJjWIdXoSRcVHRCq8w8dyeXtxJhO+2MDX2w7QpE4id1/amZv6t6FZPd3KoDxS8RGRCmvznsO8NC+dVxdsZM+hbLqGqxD827ktqFGtaqzTk0KctPiYWQ1gNlA9tH/D3R80s/bAZKAxsAi42d2PmVl1YBLQB9gFXO/uaWFb9wO3AbnAT919RogPBp4CqgLPu/tjIZ5vHyU0dhGpgNydLzfuZvycNP62fCvuzuVdz2DUoHb0a99IVyGoIIqy53MUuNTdD5hZNeBzM5sO/AJ40t0nm9mzRIrK2PBzt7t3MrPhwB+A682sKzAc6Aa0BD4yszNDH88AlwEZwEIzm+buK8O6+fUhIpXMsZw83l+2mRfnpLE0Yy/1aiRw2/ntuXlAW11VugI6afFxdwcOhKfVwsOBS4EbQ3wi8BCRwjAsLAO8ATxtkT9FhgGT3f0osMHMUoF+oV2qu68HMLPJwDAzW1VIHyJSSew8cJS/ztvIy/PT2bH/KB2b1uaRq7pzTa9W1NZVpSusIr1zZlaVyGGvTkT2UtYBe9w9JzTJAFqF5VbAJgB3zzGzvUQOm7UC5kVtNnqdTSfE+4d1CupDROLc8asQvLU4k2M5eVx4ZlP+59p2XNi5qa5CEAeKVHzcPRfoaWYNgLeBLqWa1Skys9HAaIA2bdrEOBsROV25ec5Hq7Yx8Yu0f1yF4Hu9W/HDCzrQsWmdWKcnJeiU9lndfY+ZzQIGAg3MLCHsmSQBmaFZJtAayDCzBKA+kYkHx+PHRa+TX3xXIX2cmNc4YBxAcnKyn8qYRCT2Dh7NYUrKJl74fAMZuw/TUlchiHtFme3WFMgOhacmkYkBfwBmAdcSmY02EpgaVpkWns8Nr3/i7m5m04BXzOwJIhMOOgMLAAM6h5ltmUQmJdwY1imoDxGJAzv2H2XS3DQmzU1n7+Fskts25DdDz+ayrs1J0FUI4lpR9nxaABPDeZ8qwBR3f8/MVgKTzexRYDHwQmj/AvBSmFCQRaSY4O4rzGwKsBLIAX4SDudhZncBM4hMtR7v7ivCtu4toA8RqcDW7TjAc7PX89aXmWTn5XHZ2c350UUd6dO2YaxTkzJikcls8SM5OdlTUlJinYaI5CMlLYtnP1vHx6u3U61qFb7fJ4lbz2+v8znlgJktcvfksupP8xRFpFTl5Tmffr2dZz9dz4K0LBrVTuTuSzox4rx2NKlTPdbpSYyo+IhIqcjJzeO9pVt4elYqqdsP0LJ+DX77nbP5Qf+21EzUpW8qOxUfESlRh4/lMiVlE8/9fT0Zuw9zZvM6/O/1PRl6TgsSEzSJQCJUfESkROw6cJSJX6QxaV46ew5l07tNAx78bje+1UW3ppZ/peIjIsWyKesQz/19PVNSNnE0J4/Luzbnhxd0oG+7RrFOTcoxFR8ROS0rN+/j2c/W8f6yLVQxuKZXEqMv0pUIpGhUfESkyNydeesj06U/+3oHtROrctv57bl1UHvOqK+btknRqfiIyEnl5TkfrtzK2M/W89WmPTSpk8g9V5zFTQPaUr9mtVinJxWQio+IFOhoTi5vf5nJuNnrWb/zIG0b1+LRq7pzbZ8k3SlUikXFR0T+xf4j2bwyfyMvfL6B7fuP0r1VPZ6+sRdDuregqmauSQlQ8RGRf9i+/wgvzknj5Xnp7D+Sw6BOjXniup4M6tRYt6eWEqXiIyKk7TzIX2av580vM8jOzWNo9xbccVFHzkmqH+vUJE6p+IhUYssy9vLsZ+v4YPkWqlWtwvd6JzH6wg60b1I71qlJnFPxEalk3J3PU3fy7GfrmJO6i7rVE7jjoo6MGtSOZnU1XVrKhoqPSCWRk5vH9OVb+cvsdSzP3EezutW5f0gXbuzfhro1NF1aypaKj0icO5Kdy+uLMnhu9no2Zh2iQ5PaPHbNOVzduxXVEzRdWmJDxUckTu09lM3L89N5cc4Gdh44Ro/WDfj10C5c1vUMTZeWmFPxEYkzW/ce4cU5G3h5XjoHj+Vy4ZlNueOiDgzsoOnSUn6o+IjEiYzdhxj76TqmpGwiN8/5zrktueOiDnRrqenSUv6ctPiYWWtgEtAccGCcuz9lZg8BtwM7QtNfu/sHYZ37gduAXOCn7j4jxAcDTwFVgefd/bEQbw9MBhoDi4Cb3f2YmVUPffcBdgHXu3taCYxbJG6kbj/A2E/XMXVJJmZwXXJrfnRhR9o0rhXr1EQKVJQ9nxzgl+7+pZnVBRaZ2czw2pPu/qfoxmbWFRgOdANaAh+Z2Znh5WeAy4AMYKGZTXP3lcAfwrYmm9mzRArX2PBzt7t3MrPhod31xRmwSLxYnrmXZ2al8rcVW6meUIURA9tx+4XtaVG/ZqxTEzmpkxYfd98CbAnL+81sFdCqkFWGAZPd/SiwwcxSgX7htVR3Xw9gZpOBYWF7lwI3hjYTgYeIFJ9hYRngDeBpMzN39yKPUCTOrN22nz99uIYZK7ZRt0YCd17ckVsHtadxneqxTk2kyE7pnI+ZtQN6AfOBQcBdZjYCSCGyd7SbSGGaF7VaBv8sVptOiPcncqhtj7vn5NO+1fF13D3HzPaG9jtPyGs0MBqgTZs2pzIkkQpjw86DPPXR10z9ajO1ExP4+bc7c+v57amn7+hIBVTk4mNmdYA3gZ+7+z4zGws8QuQ80CPA48CtpZLlSbj7OGAcQHJysvaKJK5syjrE05+k8saXGVSraoy+sAN3XNiRhrUTY52ayGkrUvExs2pECs9f3f0tAHffFvX6c8B74Wkm0Dpq9aQQo4D4LqCBmSWEvZ/o9se3lWFmCUD90F4k7mXsPsT/fRwpOlXNGDGwLT++uKMugSNxoSiz3Qx4AVjl7k9ExVuE80EAVwPLw/I04BUze4LIhIPOwALAgM5hZlsmkUkJN7q7m9ks4FoiM95GAlOjtjUSmBte/0TneyTebd5zmLGfrmPywo0Yxs0D2vKjizpoIoHElaLs+QwCbgaWmdmSEPs1cIOZ9SRy2C0N+BGAu68wsynASiIz5X7i7rkAZnYXMIPIVOvx7r4ibO9eYLKZPQosJlLsCD9fCpMWsogULJG4tPdQNk/PWsukuenk5jnfT27N3Zd2omUDFR2JPxZvOxLJycmekpIS6zREiiwvz3nzywwem76a3YeOcVWvVvzisjNJaqjv6UjZMbNF7p5cVv3pCgciMbRi814emLqCRem76dO2IZOG9dMVCaRSUPERiYF9R7J54sOvmTQ3jYa1Evmfa8/le72TqKILfkoloeIjUobcnbcXZ/L7D1aTdfAoNw1oyy8vO4v6tfRdHalcVHxEysjqrft44J0VLEjLomfrBkwY1ZfurXSITSonFR+RUrb/SDb/+9FaJnyRRr0aCfzhe+fw/T6tdYhNKjUVH5FS4u5M+2ozj76/ip0HjnJDvzb86oqzaFBLVyYQUfERKQVrt+3nP6cuZ976LM5Nqs/zI5Lp0bpBrNMSKTdUfERK0IGjOYz5eC3jP99A7eoJ/NfV3Rnet41uWy1yAhUfkRLg7ry/bAuPvreKrfuOMLxva341uAuNdPFPkXyp+IgUU+r2Azw0bQWfp+6kW8t6/Pmm3vRu0zDWaYmUayo+Iqfp0LEc/u+TVJ7/+3pqVqvKI8O6cWP/tjrEJlIEKj4ip8jd+dvyrTzy3ko27z3CtX2SuG9IF5roTqIiRabiI3IKNuw8yIPTVjD76x2c3aIeY27oRXK7RrFOS6TCUfERKYLDx3J5ZlYq42avp3pCFR78blduHtCWhKpVYp2aSIWk4iNSCHdn5spt/O7dlWTuOcw1vVpx39AuupuoSDGp+IgUYFPWIX737go+WrWds5rX5bXRA+jfoXGs0xKJCyo+IifIyc3jpXnp/PFvazCDXw/twqhB7ammQ2wiJUbFRyTKovTdPDB1OSs27+OiM5vy+2vOoZVuYy1S4k76p5yZtTazWWa20sxWmNnPQryRmc00s7XhZ8MQNzMbY2apZrbUzHpHbWtkaL/WzEZGxfuY2bKwzhgzs8L6EClpew9lc8/rX/G9sV+w88BR/vyD3kwY1VeFR6SUFOU4Qg7wS3fvCgwAfmJmXYH7gI/dvTPwcXgOMAToHB6jgbEQKSTAg0B/oB/wYFQxGQvcHrXe4BAvqA+REuHuTF2SySWPf8pbizO546KOfPLLixl6TgvC30AiUgpOetjN3bcAW8LyfjNbBbQChgEXh2YTgU+Be0N8krs7MM/MGphZi9B2prtnAZjZTGCwmX0K1HP3eSE+CbgKmF5IHyLFtnnPYR6atoIPV26jZ+sG/P7qc+jasl6s0xKpFE7pnI+ZtQN6AfOB5qEwAWwFmoflVsCmqNUyQqyweEY+cQrpQ+S05eTmMWluOo9/uIZcd+4f0oUfXtBBl8URKUNFLj5mVgd4E/i5u++LPiTh7m5mXgr5FakPMxtN5BAfbdq0Kc00pIJL3b6fX76+lK827eGiM5vy6FXdad2oVqzTEql0ilR8zKwakcLzV3d/K4S3mVkLd98SDqttD/FMoHXU6kkhlsk/D6Edj38a4kn5tC+sj29w93HAOIDk5ORSLYJSMWXn5jH+8w08PvNraidW5anhPbmyR0ud1xGJkaLMdjPgBWCVuz8R9dI04PiMtZHA1Kj4iDDrbQCwNxw6mwFcbmYNw0SDy4EZ4bV9ZjYg9DXihG3l14dIkS3L2Muwp+fw39NXc9GZTZnx7xcyrGcrFR6RGCrKns8g4GZgmZktCbFfA48BU8zsNiAduC689gEwFEgFDgGjANw9y8weARaGdg8fn3wA3AlMAGoSmWgwPcQL6kPkpI5k5/LkR1/z3Oz1NKlTnWdv6sMV3Zqr6IiUAxaZlBY/kpOTPSUlJdZpSIwtTMvinte/Im3XIYb3bc39Q8+mfs1qsU5LpNwys0XunlxW/ekKBxJXDh3L4X9mrGHCF2kkNazJKz/sz3mdmsQ6LRE5gYqPxI3563fxqzeXkr7rEDcPaMt9Q7pQu7p+xUXKI/3PlArv0LEc/vi3yN5Om0a1ePX2AQzsqKtPi5RnKj5SoX25cTe/eG0J6VmHGDWoHfdccRa1EvVrLVLe6X+pVEhHc3J5YmZkJluL+jV59fYBDNC9dkQqDBUfqXBWbN7LL177ijXb9jO8b2t+/Z2zqVdDM9lEKhIVH6kwcnLzGPvpOp76eC2Naify4i19uaRLs1inJSKnQcVHKoR1Ow7wiylf8dWmPVzZoyUPD+tGg1qJsU5LRE6Tio+Ua3l5zsS5aTw2fTU1E6vy9I29+LdzW8Y6LREpJhUfKbc27znMPW98xZzUXVzapRmPXXMOzerViHVaIlICVHykXJq6JJPfvrOc3Dzn91efww39WuuabCJxRMVHypW9h7L5z6nLmfbVZnq3acCT1/ekbePasU5LREqYio+UG39fu4N7Xl/KjgNH+eVlZ/LjizuSUPWkd/0QkQpIxUdiLjs3j6c+Wsszn6bSoUltnhsxiHOS6sc6LREpRSo+ElObsg7x08mLWbxxD9/vk8TDw7pTM7FqrNMSkVKm4iMx897Szdz/5jIAxtzQiyt7aAq1SGWh4iNl7tCxHB5+dyWTF26iV5sGjBnei9aNasU6LREpQyo+UqZWbt7H3a9+yfqdB/nJJR35+bfPpJomFYhUOio+UibcnYlfpPH7D1bToFY1Xr6tP4N0h1GRSuukf3Ka2Xgz225my6NiD5lZppktCY+hUa/db2apZrbGzK6Iig8OsVQzuy8q3t7M5of4a2aWGOLVw/PU8Hq7khq0lK2sg8e4fVIKD727kvM7N2H6zy5Q4RGp5IpyvGMCMDif+JPu3jM8PgAws67AcKBbWOfPZlbVzKoCzwBDgK7ADaEtwB/CtjoBu4HbQvw2YHeIPxnaSQXzxbqdDHlqNrO/3smD3+3KCyOTaVyneqzTEpEYO2nxcffZQFYRtzcMmOzuR919A5AK9AuPVHdf7+7HgMnAMItcL+VS4I2w/kTgqqhtTQzLbwDfMl1fpcLIzs3jTzPW8IPn51O7egJv/+Q8Rg1qr0vkiAhQtD2fgtxlZkvDYbmGIdYK2BTVJiPECoo3Bva4e84J8W9sK7y+N7T/F2Y22sxSzCxlx44dxRiSlIRNWYe4/i9zeXpWKt/vk8R7d59Pt5b60qiI/NPpFp+xQEegJ7AFeLzEMjoN7j7O3ZPdPblp06axTKXS+2DZFoaO+Ttrtx1gzA29+OO1PaiVqHktIvJNp/Wp4O7bji+b2XPAe+FpJtA6qmlSiFFAfBfQwMwSwt5NdPvj28owswSgfmgv5dCR7Fwefm8lr8zfSM/WDfi/G/TdHREp2Gnt+ZhZi6inVwPHZ8JNA4aHmWrtgc7AAmAh0DnMbEskMilhmrs7MAu4Nqw/Epgata2RYfla4JPQXsqZr7ft56pn5vDK/I386KIOTPnRQBUeESnUSfd8zOxV4GKgiZllAA8CF5tZT8CBNOBHAO6+wsymACuBHOAn7p4btnMXMAOoCox39xWhi3uByWb2KLAYeCHEXwBeMrNUIhMehhd7tFKi3J1XF2zid++uoG6NBF4c1ZdLzmoW67REpAKweNuZSE5O9pSUlFinEff2Hcnm/reW8f7SLVzQuQlPXNeTpnU1hVqkojKzRe6eXFb96UywnLJVW/bx45cXsWn3YX41+CzuuLAjVapoCrWIFJ2KjxSZuzMlZRMPTF1Bg1rVmDx6AH3bNYp1WiJSAan4SJEcOJrDA+8s563FmZzXsTFPDe+lw2wictpUfOSkVmzey92vLmbDzoP8/NudufvSzlTVYTYRKQYVHynU6ymb+O07y6lfsxqv/HAAAzvme5EJEZFTouIj+TqWk8cj763kpXnpnNexMWNu6EUTXRBUREqIio/8i+37jjD6pUUs2bSH0Rd24FdXnEWCbvgmIiVIxUe+YVF6Fnf+9Uv2H8nhmRt7851zW5x8JRGRU6TiI0BkGvVL89J5+N2VtGxQkxfv6EfXlvVinZaIxCkVH+FIdi6/eXs5b36ZwaVdmvHk9T2pX7NarNMSkTim4lPJZew+xB0vL2J55j5+9q3O/OxbnXW1AhEpdSo+ldii9CxGT1rEsdw8nh+RzLe7No91SiJSSaj4VFJTl2TyqzeW0rJBTZ4bkUynZnVinZKIVCIqPpVMXp7zpw/X8OdP19GvfSOevakPjWonxjotEalkVHwqkb2Hs/nFa0v4ePV2bujXmt9d2Z3EBH1/R0TKnopPJXH8NggZuw/zuyu7MWJgW8w0sUBEYkPFpxJ468sMfv32MurVqMarug2CiJQDKj5x7GhOLg+/u5K/zt/IgA6NGHNDL5rVrRHrtEREOOkBfzMbb2bbzWx5VKyRmc00s7XhZ8MQNzMbY2apZrbUzHpHrTMytF9rZiOj4n3MbFlYZ4yFY0EF9SFFs3nPYa57di5/nb+RH13UgZdv66/CIyLlRlHONk8ABp8Quw/42N07Ax+H5wBDgM7hMRoYC5FCAjwI9Af6AQ9GFZOxwO1R6w0+SR9yEgvTsvjOmL+Tuv0Az97Uh/uHnK0Lg4pIuXLSTyR3nw1knRAeBkwMyxOBq6LikzxiHtDAzFoAVwAz3T3L3XcDM4HB4bV67j7P3R2YdMK28utDCjF1SSY3PjePBrUSeffu8xnc/YxYpyQi8i9O95xPc3ffEpa3Ase/Gt8K2BTVLiPECotn5BMvrA/Jh7szbvZ6/nv6avq3b8S4m5OpX0vXZxOR8qnYEw7c3c3MSyKZ0+3DzEYTOcxHmzZtSjOVculYTh6/eXsZry/K4DvntODx63pQo1rVWKclIlKg0z0RsC0cMiP83B7imUDrqHZJIVZYPCmfeGF9/At3H+fuye6e3LRp09McUsW093A2I8cv4PVFGfz0W515+sZeKjwiUu6dbvGZBhyfsTYSmBoVHxFmvQ0A9oZDZzOAy82sYZhocDkwI7y2z8wGhFluI07YVn59SLBlb2RGW0p6Fk9c14NfXHamvjgqIhXCSQ+7mdmrwMVAEzPLIDJr7TFgipndBqQD14XmHwBDgVTgEDAKwN2zzOwRYGFo97C7H5/EcCeRGXU1genhQSF9CPD1tv2MHL+A/UdymDCqH4M6NYl1SiIiRWaRSWbxIzk52VNSUmKdRqlamJbFbRMWUr1aVSaM6ku3lvVjnZKIVHBmtsjdk8uqP13hoIL52/Kt/HTyYpIa1mTiqH60blQr1imJiJwyFZ8K5KV56TwwdTk9khow/pa+uhWCiFRYKj4VgLvz+Idf8/SsVL7VpRlP39ibmoma0SYiFZeKTzmXk5vHr99expSUDK5Pbs1/Xd1dl8oRkQpPxaccO3wsl7tf/ZKPVm3np5d24t81lVpE4oSKTzm1ff8RfjgxhWWZe3lkWDduHtgu1imJiJQYFZ9yaM3W/dzy4gL2HMpm3M3JXNZVl7UTkfii4lPOzFu/i9snpVCzWlXe+PFAfYdHROKSik85Mmv1du54eRGtG9Viwqi+JDXUd3hEJD6p+JQT7y/dws9fW8xZZ9Rl0q399R0eEYlrKj7lwOspm7j3zaX0btOQ8aP6Uq+G7sMjIvFNxSfGJn6RxoPTVnBB5yY/OkQlAAALOUlEQVT85eY+1ErUWyIi8U+fdDH07GfreGz6ai7r2pynb+xF9QRdtUBEKgcVnxh5/u/reWz6ar7boyVPXNeDarpqgYhUIio+MfDinA08+v4qvnNOC568roculyMilY4+9crYpLlp/O7dlQzudgb/O7ynCo+IVEr65CtDL89L54GpK7isa3PG3NBLh9pEpNLSp18ZmbxgI799ZznfPrsZz9zYm8QE/dOLSOWlT8AyMCVlE/e/vYxLzmrKMz9Q4RERKdanoJmlmdkyM1tiZikh1sjMZprZ2vCzYYibmY0xs1QzW2pmvaO2MzK0X2tmI6PifcL2U8O6Fe5+Am8uyuDeN5dyfqcmjL2pj6ZTi4hQMns+l7h7T3dPDs/vAz52987Ax+E5wBCgc3iMBsZCpFgBDwL9gX7Ag8cLVmhze9R6g0sg3zLzzuJM/uONrzivY2OeG5FMjWoqPCIiUDqH3YYBE8PyROCqqPgkj5gHNDCzFsAVwEx3z3L33cBMYHB4rZ67z3N3ByZFbavcm/bVZn4xZQn92zfi+RF9VXhERKIUt/g48KGZLTKz0SHW3N23hOWtwPGb0bQCNkWtmxFihcUz8on/CzMbbWYpZpayY8eO4oynRHyyehv//toSkts1YvwtfamZqMIjIhKtuF8yPd/dM82sGTDTzFZHv+jubmZezD5Oyt3HAeMAkpOTS72/wsxdt4s7Xv6Ss1vU5YWRybpWm4hIPoq15+PumeHnduBtIudstoVDZoSf20PzTKB11OpJIVZYPCmfeLm1ass+Rk9KoW2jWrx0a3/q6urUIiL5Ou3iY2a1zazu8WXgcmA5MA04PmNtJDA1LE8DRoRZbwOAveHw3AzgcjNrGCYaXA7MCK/tM7MBYZbbiKhtlTvb9x/htgkLqV09gYm39qOh7scjIlKg4hwTag68HWY/JwCvuPvfzGwhMMXMbgPSgetC+w+AoUAqcAgYBeDuWWb2CLAwtHvY3bPC8p3ABKAmMD08yp0j2bmMnrSI3Yeyef2OgbRsUDPWKYmIlGsWmUgWP5KTkz0lJaXM+nN3/v21JbyzZDPP3tSbwd1blFnfIiIlxcwWRX1lptTpq/bFNObjVN5Zspl7rjhLhUdEpIhUfIrhncWZPPnR11zTuxV3Xtwx1umIiFQYKj6naVnGXu59cyn92jfiD987lwp45R8RkZhR8TkNmXsOM/qlFJrUqc6ff9Bbt0YQETlF+tQ8RYeO5fDDiSkcOJLDcyOSaVKneqxTEhGpcPT1+1Pg7vzqjaWs3rqP8bf0pWvLerFOSUSkQtKezyl44fMNvLd0C/dccRaXnNUs1umIiFRYKj5FtDAti/+evporujXnxxdpZpuISHGo+BTBrgNHufuVxSQ1rMmfvt9DM9tERIpJ53xOwt25982lZB08xlt3nqeLhYqIlADt+ZzEqws28dGq7dw7pAvdW9WPdToiInFBxacQ6bsO8uj7KxnUqTGjzmsX63REROKGik8B8vKce95YSlUz/ufaHlSpovM8IiIlRcWnAC/NS2fBhiz+87tddYsEEZESpuKTj50HjvL4h2s4v1MTvt8n6eQriIjIKVHxyccf/7aaw9m5PHRlV02rFhEpBSo+J1ieuZfXF2Vwy3nt6NSsbqzTERGJSyo+J/j9B6toVCuRu7/VOdapiIjErXJffMxssJmtMbNUM7uvNPuau24XX6zbxU8u6UQ9fZlURKTUlOviY2ZVgWeAIUBX4AYz61pa/Y2bvY4mdapzY/82pdWFiIhQzosP0A9Idff17n4MmAwMK42O0nYeZNaaHdw0oA01qlUtjS5ERCQo78WnFbAp6nlGiJW4d7/aDMD1fVuXxuZFRCRKeS8+RWJmo80sxcxSduzYcVrbaF6vBtclJ9Givr5QKiJS2sp78ckEondFkkLsG9x9nLsnu3ty06ZNT6uj6/q25o/X9ji9LEVE5JSU9+KzEOhsZu3NLBEYDkyLcU4iIlJM5fp+Pu6eY2Z3ATOAqsB4d18R47RERKSYynXxAXD3D4APYp2HiIiUnPJ+2E1EROKQio+IiJQ5FR8RESlzKj4iIlLmVHxERKTMmbvHOocSZWY7gPTTXL0JsLME0ykP4nFMEJ/j0pgqhngcE8BZ7l5mNzEr91OtT5W7n94lDgAzS3H35JLMJ9bicUwQn+PSmCqGeBwTRMZVlv3psJuIiJQ5FR8RESlzKj7fNC7WCZSCeBwTxOe4NKaKIR7HBGU8rribcCAiIuWf9nxERKTMqfgEZjbYzNaYWaqZ3RfrfADMLM3MlpnZkuMzUcyskZnNNLO14WfDEDczGxPyX2pmvaO2MzK0X2tmI6PifcL2U8O6VlgfxRjHeDPbbmbLo2IxG0dhfRRzTA+ZWWZ4v5aY2dCo1+4P/a0xsyui4vn+3oXbiMwP8dfCLUUws+rheWp4vd3J+jiFMbU2s1lmttLMVpjZz0K8wr5XhYypwr5XZlbDzBaY2VdhTL8r6TxKcqwFcvdK/yByu4Z1QAcgEfgK6FoO8koDmpwQ+yNwX1i+D/hDWB4KTAcMGADMD/FGwPrws2FYbhheWxDaWlh3SGF9FGMcFwK9geXlYRwF9VECY3oI+I982nYNv1PVgfbhd61qYb93wBRgeFh+FvhxWL4TeDYsDwdeK6yPUxxTC6B3WK4LfB22W2Hfq0LGVGHfq/BvUScsVwPmh3+bEsmjJMda6DiK86ESLw9gIDAj6vn9wP3lIK80/rX4rAFahOUWwJqw/BfghhPbATcAf4mK/yXEWgCro+L/aFdQH8UcSzu++UEds3EU1EcJjOkh8v9A+8bvE5H7Uw0s6PeOyIfLTiDhxN/P4+uG5YTQzgrqo5jv2VTgsnh4r/IZU1y8V0At4Eugf0nlUZJjLSx3HXaLaAVsinqeEWKx5sCHZrbIzEaHWHN33xKWtwLNw3JBYygsnpFPvLA+SlIsx1Ga7/dd4fDQePvn4cpTHVNjYI+75+ST3z/WCa/vDe1LdEzhsEkvIn9Vx8V7dcKYoAK/V2ZW1cyWANuBmUT2VEoqj5Ica4FUfMq38929NzAE+ImZXRj9okf+zCjV6Yrq45SMBToCPYEtwOOl3F+pMLM6wJvAz919X/RrFfW9ymdMFfq9cvdcd+8JJAH9gC4xTumUqfhEZAKto54nhVhMuXtm+LkdeJvIL9k2M2sBEH5uD80LGkNh8aR84hTSR0mK5ThK5f12923hQyEPeI7I+3U6Y9oFNDCzhBPi39hWeL1+aF8iYzKzakQ+pP/q7m+FcIV+r/IbUzy8V2Ece4BZRA6BlVQeJTnWAqn4RCwEOoeZHIlETphNi2VCZlbbzOoeXwYuB5aHvI7PHhpJ5Bg2IT4izA4aAOwNhzFmAJebWcNwaOFyIsdptwD7zGyAmRkw4oRt5ddHSYrlOArqo1iOf3gGVxN5v473NzzMCGoPdCZy4j3f37vwl/8s4NoCcj8+pmuBT0L7gvo4lfwNeAFY5e5PRL1UYd+rgsZUkd8rM2tqZg3Cck0i57BWlWAeJTnWgp3uibt4exCZVfM1kWOnvykH+XQgMsvkK2DF8ZyIHEf9GFgLfAQ0CnEDngn5LwOSo7Z1K5AaHqOi4slE/tOtA57mn186zrePYozlVSKHNrKJHCe+LZbjKKyPYo7ppbC9peE/Y4uo9r8J/a0hzPAq7PcuvP8LwlhfB6qHeI3wPDW83uFkfZzCmM4ncrhrKbAkPIZW5PeqkDFV2PcKOBdYHHJfDjxQ0nmU5FgLeugKByIiUuZ02E1ERMqcio+IiJQ5FR8RESlzKj4iIlLmVHxERKTMqfiIiEiZU/EREZEyp+IjIiJl7v8BocdVdcobfzEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_tokens, n_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anyala/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (как написано выше)\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthursaprykin/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/arthursaprykin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78     29147\n",
      "    positive       0.76      0.79      0.78     27562\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация\n",
    "\n",
    "У каждого слова есть лемма (нормальная форма):\n",
    "\n",
    "    кошке, кошку, кошкам, кошкой ⟹ кошка\n",
    "    бежал, бежит, бегу ⟹ бежать\n",
    "    белому, белым, белыми ⟹ белый\n",
    "\n",
    "\n",
    "**Лемматизация** – это приведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from pymystem3) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (1.24.2)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'каждый',\n",
       "    'wt': 0.9985975799,\n",
       "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хотеть',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте терепь использовать лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopwords_ru = set(stopwords.words('russian'))\n",
    "stopwords_ru.update([' ', '\\n'])\n",
    "\n",
    "def my_preproc(text, stopwords = stopwords_ru):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthursaprykin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.75     28862\n",
      "    positive       0.74      0.76      0.75     27847\n",
      "\n",
      "    accuracy                           0.75     56709\n",
      "   macro avg       0.75      0.75      0.75     56709\n",
      "weighted avg       0.75      0.75      0.75     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый, с большим количеством функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'платили', 2368, 10),))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишите аналогичную функцию для лемматизации с pymorphy2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будет, если использовать её в качестве препроцессора? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mystem vs. pymorphy\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = 'Действительно, на его лице не отражалось никаких чувств – ни проблеска сочувствия не было на нем, а ведь боль просто невыносима'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "действительно, на он лицо не отражаться никакой чувство – ни проблеск сочувствие не быть на нем, а ведь боль просто невыносимый\n"
     ]
    }
   ],
   "source": [
    "lemmas1 = [pymorphy2_analyzer.parse(word)[0].normal_form for word in sent1.split()]\n",
    "print(' '.join(lemmas1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "действительно, на его лицо не отражаться никакой чувство – ни проблеск сочувствие не быть на немой, а ведь боль просто невыносимый\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmas2 = mystem_analyzer.lemmatize(sent1)\n",
    "print(''.join(lemmas2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Стемминг\n",
    "\n",
    "Слова состоят из морфем: 𝑤𝑜𝑟𝑑=𝑠𝑡𝑒𝑚+𝑎𝑓𝑓𝑖𝑥𝑒𝑠. Стемминг позволяет отбросить аффиксы. Чаще всего используется алгоритм Портера.\n",
    "\n",
    "Алгоритм Портера состоит из 5 циклов команд, на каждом цикле – операция удаления / замены суффикса. Возможны вероятностные расширения алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "распределен\n",
      "пристав\n",
      "сдела\n",
      "словообразован\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import RussianStemmer\n",
    "\n",
    "stemmer = RussianStemmer()\n",
    "words = ['распределение', 'приставить', 'сделала', 'словообразование']\n",
    "for w in words:\n",
    "    stem = stemmer.stem(w)\n",
    "    print(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27980\n",
      "    positive       1.00      1.00      1.00     28729\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоило оставить пунктуацию -- и все метрики равны 1! Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32978\n",
      "    positive       0.83      1.00      0.91     23731\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.91      0.92      0.91     56709\n",
      "weighted avg       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ''\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.99      1.00      1.00     27667\n",
      "   positive       1.00      0.99      1.00     29042\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы оказываются очень значимыми.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сегментация предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знаки \".\", \"?\", \"!\" не всегда однозначно определяют границы предложений.\n",
    "\n",
    "Бинарный классификатор для сегментации предложений: для каждой точки \".\" определить, является ли она концом предложения или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rusenttokenize\n",
      "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
      "Installing collected packages: rusenttokenize\n",
      "Successfully installed rusenttokenize-0.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install rusenttokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Эта шоколадка за 400р.\n",
      "ничего из себя не представляла.\n",
      "В г.\n",
      "2019 Артём решил больше не ходить в этот магазин на берегу р. Москвы.\n",
      "\n",
      "3\n",
      "Эта шоколадка за 400р. ничего из себя не представляла.\n",
      "В г. 2019 Артём решил больше не ходить в этот магазин на берегу р.\n",
      "Москвы.\n"
     ]
    }
   ],
   "source": [
    "text = 'Эта шоколадка за 400р. ничего из себя не представляла. В г. 2019 Артём решил больше не ходить в этот магазин на берегу р. Москвы.'\n",
    "\n",
    "\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')\n",
    "\n",
    "print()\n",
    "sents = ru_sent_tokenize(text)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регулярные выражения\n",
    "Вообще, часто бывает так, что для конкретного случая нужен особый способ токенизации, и надо самостоятельно написать регулярку. Или, например, перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
    "\n",
    "Навык полезный, давайте в нём тоже потренируемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Классы символов:*__\n",
    "\n",
    "__[A-Z]__ – символы верхнего регистра (латиница)\n",
    "\n",
    "__[a-z]__ – символы нижнего регистра (латиница)\n",
    "\n",
    "__[А-Я]__ – символы верхнего регистра (кириллица)\n",
    "\n",
    "__[а-я]__ – символы нижнего регистра (кириллица)\n",
    "\n",
    "__[0-9]__ или __\\d__ – цифра\n",
    "\n",
    "__[^0-9]__ или __\\D__ – любой символ, кроме цифры\n",
    "\n",
    "__.__ – любой символ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Служебные символы:*__\n",
    "\n",
    "__\\t__ – табуляция\n",
    "\n",
    "__\\s__ – любой пробельный символ\n",
    "\n",
    "__\\S__ – все символы, кроме пробельных\n",
    "\n",
    "__\\n__ – перенос строки\n",
    "\n",
    "__^__ – начало строки\n",
    "\n",
    "__$__ – конец строки\n",
    "\n",
    "__\\__ – экранирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Операторы:*__\n",
    "\n",
    "__?__ - предыдущий символ/группа может быть, а может не быть\n",
    "\n",
    "__+__ - предыдущий символ/группа может повторяться 1 и более раз\n",
    "\n",
    "__*__ - предыдущий символ/группа может повторяться 0 и более раз\n",
    "\n",
    "__{n,m}__ - предыдущий символ/группа может повторяться от от n до m включительно\n",
    "\n",
    "__{n,}__ - предыдущий символ/группа в скобках может повторяться n и более раз\n",
    "\n",
    "__{,m}__ - предыдущий символ/группа может повторяться до m раз\n",
    "\n",
    "__{n}__ - предыдущий символ/группа повторяется n раз\n",
    "\n",
    "Внутри групп не работают операторы __.__, __+__, __*__, их необходимо экранировать с помощью обратного слеша: \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findall\n",
    "возвращает список всех найденных совпадений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abca']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос на внимательность: почему нет abcx?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Кот сидит на столе'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split\n",
    "разделяет строку по заданному шаблону\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie', ' weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно указать максимальное количество разбиений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie, weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit = 2) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sub\n",
    "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
    "\n",
    "параметры: (pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbcbbc\n"
     ]
    }
   ],
   "source": [
    "result = re.sub('a', 'b', 'abcabc')\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: напишите регулярку, которая заменяет все цифры в строке на \"DIG\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: напишите регулярку, которая убирает url из строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile\n",
    "компилирует регулярное выражение в отдельный объект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример: построение списка всех слов строки:\n",
    "prog = re.compile('[А-Яа-яё\\-]+')\n",
    "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
    "\n",
    "```\n",
    "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё ещё осталось время: [регулярочный кроссворд ¯\\_(ツ)_/¯](https://mariolurig.com/crossword/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
